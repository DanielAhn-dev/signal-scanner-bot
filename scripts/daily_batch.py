from __future__ import annotations

import os
import sys
import time
import traceback
from datetime import date, datetime, timedelta
from typing import List, Dict, Tuple

import pandas as pd
import numpy as np
from pykrx import stock
from supabase import create_client, Client

# ===== í™˜ê²½ ë³€ìˆ˜ ì„¤ì • =====
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_SERVICE_ROLE_KEY")

if not SUPABASE_URL or not SUPABASE_KEY:
    print("ğŸš¨ [Error] SUPABASE_URL or SERVICE_ROLE_KEY missing", file=sys.stderr)
    sys.exit(1)

supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# ===== ì„¹í„° ë§¤í•‘ ê·œì¹™  =====
NAME_TO_INDEX_RULES: List[Tuple[str, str]] = [
    ("ë°˜ë„ì²´", "1014"), ("ì „ìì¥ë¹„", "1013"), ("ì „ê¸°ì „ì", "1013"),
    ("í™”í•™", "1010"), ("ì² ê°•", "1011"), ("ê¸°ê³„", "1012"),
    ("ì¡°ì„ ", "1017"), ("ìš´ìˆ˜ì¥ë¹„", "1017"), ("ì€í–‰", "1027"),
    ("ë³´í—˜", "1027"), ("ê¸ˆìœµ", "1027"),
]

def infer_index_code_from_name(name: str) -> str | None:
    for kw, code in NAME_TO_INDEX_RULES:
        if kw in name: return code
    return None

# ===== ì§€í‘œ ê³„ì‚° í—¬í¼ í•¨ìˆ˜ =====
def calculate_rsi(series: pd.Series, period: int = 14):
    delta = series.diff()
    gain = (delta.where(delta > 0, 0)).fillna(0)
    loss = (-delta.where(delta < 0, 0)).fillna(0)
    avg_gain = gain.ewm(alpha=1/period, min_periods=period, adjust=False).mean()
    avg_loss = loss.ewm(alpha=1/period, min_periods=period, adjust=False).mean()
    rs = avg_gain / avg_loss
    return 100 - (100 / (1 + rs))

def calculate_avwap(df: pd.DataFrame, anchor_idx: int):
    if len(df) == 0 or anchor_idx < 0 or anchor_idx >= len(df): return None
    subset = df.iloc[anchor_idx:].copy()
    v_cumsum = subset['volume'].cumsum()
    if v_cumsum.iloc[-1] == 0: return None
    pv = (subset['close'] * subset['volume']).cumsum()
    return (pv / v_cumsum).iloc[-1]

# ===== 1. ì„¹í„° ì •ë³´ ì—…ë°ì´íŠ¸ =====
def update_sectors_meta():
    print("\n[1/5] ì„¹í„° ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸...")
    try:
        res = supabase.table("sectors").select("*").execute() # '*'ë¡œ ëª¨ë“  ì»¬ëŸ¼ ì¡°íšŒ
        rows = res.data or []
        
        updates = []
        for row in rows:
            sid = row["id"]
            name = row.get("name") or "" # ê¸°ì¡´ name ê°’ ê°€ì ¸ì˜¤ê¸°
            metrics = row.get("metrics") or {}
            
            # krx_indexê°€ ì—†ì„ ë•Œë§Œ ì¶”ë¡  ì‹œë„
            if not metrics.get("krx_index"):
                code = infer_index_code_from_name(name)
                if code:
                    new_metrics = dict(metrics)
                    new_metrics["krx_index"] = str(code)
                    
                    # [ìˆ˜ì •] upsert ì‹œ í•„ìˆ˜ í•„ë“œì¸ 'name'ë„ í•¨ê»˜ ì „ë‹¬í•´ì•¼ ì—ëŸ¬ ì•ˆ ë‚¨
                    updates.append({
                        "id": sid, 
                        "name": name,          # <-- í•µì‹¬: ê¸°ì¡´ ì´ë¦„ ë‹¤ì‹œ ë„£ì–´ì£¼ê¸°
                        "metrics": new_metrics
                    })
        
        if updates:
            print(f"  -> {len(updates)}ê°œ ì„¹í„° ë§¤í•‘ ì—…ë°ì´íŠ¸")
            for i in range(0, len(updates), 100):
                supabase.table("sectors").upsert(updates[i:i+100]).execute()
        else:
            print("  -> ì—…ë°ì´íŠ¸í•  ì„¹í„° ì—†ìŒ")
            
    except Exception as e:
        print(f"  -> ì„¹í„° ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ (ë¬´ì‹œ ê°€ëŠ¥): {e}")

# ===== 2. ë‹¹ì¼ ì‹œì„¸ ì¼ê´„ ìˆ˜ì§‘  =====
def fetch_and_save_today_market():
    today_str = date.today().strftime("%Y%m%d")
    print(f"\n[2/5] {today_str} ì „ ì¢…ëª© ì‹œì„¸ ìˆ˜ì§‘...")

    try:
        # íœ´ì¥ì¼ ì²´í¬ (ì‚¼ì„±ì „ì ê¸°ì¤€)
        check = stock.get_market_ohlcv(today_str, today_str, "005930")
        if check.empty:
            print("ğŸ”´ ì˜¤ëŠ˜ì€ íœ´ì¥ì¼ì´ê±°ë‚˜ ì¥ ë§ˆê° ì „ì…ë‹ˆë‹¤.")
            return False

        # KOSPI/KOSDAQ í•œ ë²ˆì— ìˆ˜ì§‘
        df_kospi = stock.get_market_ohlcv_by_ticker(today_str, market="KOSPI")
        df_kosdaq = stock.get_market_ohlcv_by_ticker(today_str, market="KOSDAQ")
        df_total = pd.concat([df_kospi, df_kosdaq])

        upsert_rows = []
        for ticker, row in df_total.iterrows():
            if row['ê±°ë˜ëŸ‰'] == 0: continue
            upsert_rows.append({
                "ticker": ticker,
                "date": date.today().isoformat(),
                "open": int(row["ì‹œê°€"]),
                "high": int(row["ê³ ê°€"]),
                "low": int(row["ì €ê°€"]),
                "close": int(row["ì¢…ê°€"]),
                "volume": int(row["ê±°ë˜ëŸ‰"]),
                "value": float(row["ê±°ë˜ëŒ€ê¸ˆ"]),
            })

        if upsert_rows:
            print(f"  -> {len(upsert_rows)}ê°œ ì¢…ëª© ì €ì¥ ì¤‘...")
            # 1000ê°œì”© ë°°ì¹˜ ì €ì¥ (ì†ë„ í–¥ìƒ)
            for i in range(0, len(upsert_rows), 1000):
                try:
                    supabase.table("stock_daily").upsert(upsert_rows[i:i+1000]).execute()
                except:
                    # ì—ëŸ¬ ì‹œ ë” ì‘ê²Œ ìª¼ê°œì„œ ì¬ì‹œë„
                    chunk = upsert_rows[i:i+1000]
                    for j in range(0, len(chunk), 100):
                        try: supabase.table("stock_daily").upsert(chunk[j:j+100]).execute()
                        except: pass
        return True
    except Exception as e:
        print(f"ğŸš¨ ì‹œì„¸ ìˆ˜ì§‘ ì—ëŸ¬: {e}")
        traceback.print_exc()
        return False

# ===== 3. íˆ¬ìì ìˆ˜ê¸‰ & ì„¹í„° ì§€ìˆ˜ ìˆ˜ì§‘ =====
def fetch_other_market_data():
    today_str = date.today().strftime("%Y%m%d")
    today_iso = date.today().isoformat()
    print(f"\n[3/5] íˆ¬ìì ìˆ˜ê¸‰ ë° ì„¹í„° ì§€ìˆ˜ ìˆ˜ì§‘...")

    # 3-1. íˆ¬ìì ìˆ˜ê¸‰ (ê¸°ì¡´ ë™ì¼)
    try:
        df_inst = stock.get_market_net_purchases_of_equities_by_ticker(today_str, "ALL", "ê¸°ê´€í•©ê³„")
        time.sleep(0.5)
        df_foreign = stock.get_market_net_purchases_of_equities_by_ticker(today_str, "ALL", "ì™¸êµ­ì¸")
        
        df_merged = pd.merge(df_inst, df_foreign, left_index=True, right_index=True, suffixes=('_ê¸°ê´€', '_ì™¸êµ­ì¸'))
        
        inv_rows = []
        for ticker, row in df_merged.iterrows():
            i_net, f_net = int(row['ìˆœë§¤ìˆ˜ê±°ë˜ëŒ€ê¸ˆ_ê¸°ê´€']), int(row['ìˆœë§¤ìˆ˜ê±°ë˜ëŒ€ê¸ˆ_ì™¸êµ­ì¸'])
            if i_net == 0 and f_net == 0: continue
            inv_rows.append({
                "date": today_iso, "ticker": ticker,
                "institution": i_net, "foreign": f_net
            })
        
        if inv_rows:
            for i in range(0, len(inv_rows), 1000):
                supabase.table("investor_daily").upsert(inv_rows[i:i+1000]).execute()
            print("  -> íˆ¬ìì ìˆ˜ê¸‰ ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        print(f"  -> íˆ¬ìì ìˆ˜ê¸‰ ì‹¤íŒ¨: {e}")

    # 3-2. ì„¹í„° ì§€ìˆ˜ ë° ë“±ë½ë¥  ì—…ë°ì´íŠ¸ (ìˆ˜ì •ë¨)
    try:
        # ë§¤í•‘ëœ ì„¹í„° ì¸ë±ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        res = supabase.table("sectors").select("id, metrics").execute()
        sector_rows = []
        sector_updates = [] # sectors í…Œì´ë¸” ì—…ë°ì´íŠ¸ìš©
        
        for row in (res.data or []):
            sid = row['id']
            code = row.get('metrics', {}).get('krx_index')
            if not code: continue
            
            # í•´ë‹¹ ì¸ë±ìŠ¤ì˜ ì˜¤ëŠ˜ ì‹œì„¸
            try:
                df = stock.get_index_ohlcv(today_str, today_str, code)
                if df.empty: continue
                
                val = df.iloc[0]
                close_price = float(val["ì¢…ê°€"])
                trade_value = float(val["ê±°ë˜ëŒ€ê¸ˆ"])
                change_rate = float(val["ë“±ë½ë¥ "]) # ë“±ë½ë¥  ê°€ì ¸ì˜¤ê¸°

                # 1) sector_daily í…Œì´ë¸”ìš© ë°ì´í„°
                sector_rows.append({
                    "sector_id": sid, "date": today_iso,
                    "close": close_price, "value": trade_value
                })

                # 2) sectors í…Œì´ë¸” ì—…ë°ì´íŠ¸ìš© (avg_change_rate ë°˜ì˜)
                # metrics í•„ë“œë„ ì—…ë°ì´íŠ¸ í•„ìš”í•˜ë‹¤ë©´ ì—¬ê¸°ì„œ ê°™ì´ ì²˜ë¦¬
                sector_updates.append({
                    "id": sid,
                    "avg_change_rate": change_rate, 
                    # "momentum_score": ... (í•„ìš”ì‹œ ì—¬ê¸°ì„œ ê³„ì‚°)
                })

            except Exception as e: 
                # print(f"err {sid}: {e}")
                pass
            time.sleep(0.1) 
            
        # sector_daily ì €ì¥
        if sector_rows:
            supabase.table("sector_daily").upsert(sector_rows).execute()
            print("  -> ì„¹í„° ì¼ë³„ ì§€ìˆ˜ ì €ì¥ ì™„ë£Œ")

        # sectors í…Œì´ë¸”ì— ë“±ë½ë¥ (avg_change_rate) ì—…ë°ì´íŠ¸
        if sector_updates:
            supabase.table("sectors").upsert(sector_updates).execute()
            print("  -> ì„¹í„° ë“±ë½ë¥ (avg_change_rate) ì—…ë°ì´íŠ¸ ì™„ë£Œ")

    except Exception as e:
        print(f"  -> ì„¹í„° ì§€ìˆ˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

# ===== 4. ì§€í‘œ ê³„ì‚° (í•µì‹¬) =====
def calculate_indicators():
    print("\n[4/5] ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°...")
    today_iso = date.today().isoformat()
    
    # ì˜¤ëŠ˜ ë°ì´í„°ê°€ ìˆëŠ” ì¢…ëª©ë§Œ ëŒ€ìƒ
    try:
        res = supabase.table("stock_daily").select("ticker").eq("date", today_iso).execute()
        target_tickers = [r['ticker'] for r in res.data]
    except: return

    print(f"  -> ëŒ€ìƒ ì¢…ëª©: {len(target_tickers)}ê°œ")
    
    # 50ê°œì”© ëŠì–´ì„œ ì²˜ë¦¬
    chunk_size = 50
    for i in range(0, len(target_tickers), chunk_size):
        batch = target_tickers[i : i + chunk_size]
        if i % 200 == 0: print(f"  -> ì§„í–‰: {i}/{len(target_tickers)}")
        
        upsert_buffer = []
        try:
            # 1ë…„ì¹˜ ë°ì´í„° ì¡°íšŒ
            h_res = supabase.table("stock_daily").select("*").in_("ticker", batch)\
                .gte("date", (date.today() - timedelta(days=365)).isoformat())\
                .order("date", desc=False).execute()
            
            h_df = pd.DataFrame(h_res.data)
            if h_df.empty: continue
            h_df['date'] = pd.to_datetime(h_df['date'])
            
            for ticker in batch:
                df = h_df[h_df['ticker'] == ticker].sort_values('date')
                if len(df) < 20: continue

                # ì§€í‘œ ê³„ì‚°
                close = df['close']
                df['rsi14'] = calculate_rsi(close, 14)
                
                # [ìˆ˜ì •] roc14 ê³„ì‚° ë¡œì§ ì¶”ê°€ (ì´ ë¶€ë¶„ì´ ë¹ ì ¸ì„œ ì—ëŸ¬ ë°œìƒ)
                df['roc14'] = close.pct_change(14) * 100
                df['roc21'] = close.pct_change(21) * 100
                
                # ì´í‰ì„ 
                df['sma20'] = close.rolling(20).mean()
                df['sma50'] = close.rolling(50).mean()
                df['sma200'] = close.rolling(200).mean()
                df['slope200'] = df['sma200'].diff(5)

                # 52ì£¼ ìµœì €ì  AVWAP
                avwap_val = None
                try:
                    window = min(250, len(df))
                    low_idx_date = df['low'].tail(window).idxmin()
                    idx_loc = df.index.get_loc(low_idx_date)
                    avwap_val = calculate_avwap(df, idx_loc)
                except: pass
                
                last = df.iloc[-1]
                
                def n(v): return None if pd.isna(v) or np.isinf(v) else float(v)
                def n_int(v): return None if pd.isna(v) or np.isinf(v) else int(v)
                
                upsert_buffer.append({
                    "code": ticker,
                    "trade_date": last['date'].strftime("%Y-%m-%d"),
                    "close": n(last['close']),
                    "volume": n_int(last['volume']),
                    "value_traded": n(last['value']),
                    "sma20": n(last['sma20']),
                    "sma50": n(last['sma50']),
                    "sma200": n(last['sma200']),
                    "slope200": n(last['slope200']),
                    "rsi14": n(last['rsi14']),
                    "roc14": n(last['roc14']),
                    "roc21": n(last['roc21']),
                    "avwap_breakout": n(avwap_val),
                    "updated_at": datetime.now().isoformat() 
                })
            
            if upsert_buffer:
                supabase.table("daily_indicators").upsert(upsert_buffer).execute()
                
        except Exception as e:
            print(f"  -> ë°°ì¹˜ ì—ëŸ¬: {e}")
            # ì—ëŸ¬ ì›ì¸ íŒŒì•…ì„ ìœ„í•´ ë” ìì„¸íˆ ì¶œë ¥ (í•„ìš”ì‹œ)
            # traceback.print_exc()
            continue

# ===== 5. ë°ì´í„° ì •ë¦¬ =====
def cleanup_old_data():
    print("\n[5/5] ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬...")
    cutoff = (date.today() - timedelta(days=366)).isoformat()
    try:
        supabase.table("stock_daily").delete().lt("date", cutoff).execute()
        supabase.table("investor_daily").delete().lt("date", cutoff).execute()
    except: pass

# ===== 6. ì„¹í„°ë³„ ìˆ˜ê¸‰ =====
def update_sector_investor_flows():
    print("\n[6] ì„¹í„°ë³„ ìˆ˜ê¸‰(5ì¼) ì§‘ê³„ ë° ì—…ë°ì´íŠ¸...")
    try:
        # 1. ìµœê·¼ Nì¼ì¹˜ ìˆ˜ê¸‰ ë°ì´í„°
        start_date = (date.today() - timedelta(days=10)).isoformat()
        res_inv = supabase.table("investor_daily") \
            .select("ticker, date, foreign, institution") \
            .gte("date", start_date).execute()
        df_inv = pd.DataFrame(res_inv.data)
        if df_inv.empty:
            print(" -> ì§‘ê³„í•  ìˆ˜ê¸‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ìµœê·¼ ì˜ì—…ì¼ 10ê°œë§Œ ì‚¬ìš©
        topN = 10
        topN_dates = sorted(df_inv["date"].unique(), reverse=True)[:topN]
        df_target = df_inv[df_inv["date"].isin(topN_dates)].copy()

        # 2. ì¢…ëª©-ì„¹í„° ë§¤í•‘
        res_stocks = supabase.table("stocks") \
            .select("code, sector_id") \
            .not_.is_("sector_id", "null").execute()
        df_stocks = pd.DataFrame(res_stocks.data)

        # 3. ë³‘í•©
        df_merged = pd.merge(df_target, df_stocks,
                             left_on="ticker", right_on="code", how="inner")
        if df_merged.empty:
            print(" -> ì„¹í„° ë§¤í•‘ëœ ìˆ˜ê¸‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # 4. ì„¹í„°ë³„ í•©ê³„
        df_sector_sum = df_merged.groupby("sector_id")[["institution", "foreign"]] \
                                 .sum().reset_index()

        # 4-1. ìƒìœ„ì—…ì¢… ìˆ˜ê¸‰ì„ ì„¸ë¶€ì—…ì¢…ìœ¼ë¡œ ë³µì‚¬
        PARENT_TO_CHILD = {
            "KRX:ë³´í—˜": ["KRX:ì†í•´ë³´í—˜", "KRX:ìƒëª…ë³´í—˜"],
            "KRX:ê¸ˆìœµ": ["KRX:ì€í–‰", "KRX:ê¸°íƒ€ê¸ˆìœµ"],
            "KRX:ê¸°ê³„Â·ì¥ë¹„": ["KRX:ê¸°ê³„"],
        }
        extra_rows = []
        for _, row in df_sector_sum.iterrows():
            parent_id = row["sector_id"]
            for cid in PARENT_TO_CHILD.get(parent_id, []):
                extra_rows.append({
                    "sector_id": cid,
                    "institution": row["institution"],
                    "foreign": row["foreign"],
                })
        if extra_rows:
            df_sector_sum = pd.concat(
                [df_sector_sum, pd.DataFrame(extra_rows)],
                ignore_index=True,
            )

        # 5. sectors.metrics ì—…ë°ì´íŠ¸
        res_sectors = supabase.table("sectors").select("id, name, metrics").execute()
        sector_map = {
            r["id"]: {
                "name": r.get("name"),
                "metrics": r.get("metrics") or {},
            }
            for r in res_sectors.data
        }

        updates = []
        for _, row in df_sector_sum.iterrows():
            sid = row["sector_id"]
            inst = int(row["institution"])
            fore = int(row["foreign"])

            existing = sector_map.get(sid)
            if not existing:
                continue

            m = dict(existing["metrics"] or {})
            prev_i = int(m.get("flow_inst_5d") or 0)
            prev_f = int(m.get("flow_foreign_5d") or 0)
            m["flow_inst_5d"] = prev_i + inst
            m["flow_foreign_5d"] = prev_f + fore

            updates.append({
                "id": sid,
                "name": existing["name"],
                "metrics": m,
                "updated_at": datetime.now().isoformat(),
            })

        # id ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±°
        unique_updates: dict[str, dict] = {}
        for u in updates:
            sid = u["id"]
            if sid in unique_updates:
                mp = unique_updates[sid]["metrics"]
                mn = u["metrics"]
                mp["flow_inst_5d"] = int(mp.get("flow_inst_5d") or 0) + int(mn.get("flow_inst_5d") or 0)
                mp["flow_foreign_5d"] = int(mp.get("flow_foreign_5d") or 0) + int(mn.get("flow_foreign_5d") or 0)
            else:
                unique_updates[sid] = u

        final_updates = list(unique_updates.values())
        if final_updates:
            print(f" -> {len(final_updates)}ê°œ ì„¹í„° ìˆ˜ê¸‰ ì •ë³´(metrics) ì—…ë°ì´íŠ¸ ì¤‘...")
            for i in range(0, len(final_updates), 100):
                supabase.table("sectors").upsert(final_updates[i:i+100]).execute()
            print(" âœ… ì„¹í„° ìˆ˜ê¸‰ ì§‘ê³„ ì™„ë£Œ")

    except Exception as e:
        print(f"ğŸš¨ ì„¹í„° ìˆ˜ê¸‰ ì§‘ê³„ ì‹¤íŒ¨: {e}")
        traceback.print_exc()

if __name__ == "__main__":
    print(f"ğŸš€ Daily Batch Start: {datetime.now()}")
    
    update_sectors_meta()
    
    if fetch_and_save_today_market():
        fetch_other_market_data()
        update_sector_investor_flows()
        calculate_indicators()
        cleanup_old_data()
        
    print("ğŸ Daily Batch End")